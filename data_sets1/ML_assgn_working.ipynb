{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decisionNode:\n",
    "    def __init__(self,col=-1,value=None,results=None,tb=None,fb=None):\n",
    "        self.col=col # column index of criteria being tested\n",
    "        self.value=value # vlaue necessary to get a true result\n",
    "        self.results=results # dict of results for a branch, None for everything except endpoints\n",
    "        self.tb=tb # true decision nodes \n",
    "        self.fb=fb # false decision nodes\n",
    "        self.leaf = False\n",
    "        self.depth = 0\n",
    "        self.sample_max = None\n",
    "    def assignAttributes(self,col=-1,value=None,results=None,tb=None,fb=None,lf=False,dp=0,max_sample = None):\n",
    "        self.col=col # column index of criteria being tested\n",
    "        self.value=value # vlaue necessary to get a true result\n",
    "        self.results=results # dict of results for a branch, None for everything except endpoints\n",
    "        self.tb=tb # true decision nodes \n",
    "        self.fb=fb # false decision nodes\n",
    "        self.leaf = lf\n",
    "        self.depth = dp\n",
    "        self.sample_max = max_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "log2=lambda x:log(x)/log(2)\n",
    "tem = {0 : 'negative' , 1 : 'positive'}\n",
    "tem_rev = {'negative' : 0 , 'positive' : 1}\n",
    "t = {}\n",
    "def get_entropy(df,columns,returnVal='IG'):\n",
    "    data_0 = df.loc[df[columns[0]] == 0 ,columns ]\n",
    "    data_1 = df.loc[df[columns[0]] == 1 ,columns ]\n",
    "    data_counts_0 = get_unique_data_counts(data_0)\n",
    "    data_counts_1 = get_unique_data_counts(data_1)\n",
    "    data_counts = [data_counts_0 , data_counts_1]\n",
    "    results = {}\n",
    "    column_Entr = {} \n",
    "    total_Entropy = {}\n",
    "    for column in columns:\n",
    "        results[column] = {'negative' : [] , 'positive': []}\n",
    "        column_Entr[column] = []\n",
    "    for data in data_counts:\n",
    "        for obj in data.items():\n",
    "            total = 0\n",
    "            for values in obj[1].items():\n",
    "                total = total + values[1]\n",
    "            column_Entr[obj[0]].append(total)\n",
    "    #print('colmEntr : ' , column_Entr)\n",
    "    if returnVal == 'IG':\n",
    "        entropies = {}\n",
    "        try:\n",
    "            for values in column_Entr:\n",
    "                entropy = 0\n",
    "                for value in column_Entr[values]:\n",
    "                    #print(column_Entr[values])\n",
    "                    p=float(value)/sum(column_Entr[values]) \n",
    "                    entropy=entropy-p*log2(p)\n",
    "                column_Entr[values]=entropy\n",
    "            for data in data_counts:\n",
    "                for obj in data.items():\n",
    "                    for d in obj[1].items():\n",
    "                        results[obj[0]][tem[d[0]]].append(d[1])\n",
    "            for r in results.items():\n",
    "                t = {}\n",
    "                for data in results[r[0]].items():\n",
    "                    #print('sum : ', sum(data[1]) )\n",
    "                    entropy = 0\n",
    "                    for value in data[1]:\n",
    "                        p=float(value)/sum(data[1]) \n",
    "                        entropy=entropy-p*log2(p)\n",
    "                    t[tem_rev[data[0]]] = entropy\n",
    "                t['overall'] = column_Entr[r[0]]\n",
    "                entropies[r[0]]=t    \n",
    "        except:\n",
    "            pass\n",
    "        return entropies \n",
    "    elif returnVal == 'VI':\n",
    "        impurities = {}\n",
    "        try:\n",
    "            for values in column_Entr:\n",
    "                impurity = 1\n",
    "                for value in column_Entr[values]:\n",
    "                    #print(sum(column_Entr[values]))\n",
    "                    impurity= impurity*float(value)/sum(column_Entr[values]) \n",
    "                impurities[values]=impurity    \n",
    "        except:\n",
    "            pass\n",
    "        return impurities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_InformationGain(df, S , A , type_R= 'IG'):\n",
    "    columns = [S,A]\n",
    "    summation = 0\n",
    "    entropy_s = 0\n",
    "    if not df.empty:\n",
    "        entropies = get_entropy(df, columns,type_R)\n",
    "        if len(entropies) >0:\n",
    "            if type_R == 'IG' :\n",
    "                entropy_s = entropies[S]['overall']\n",
    "            else : \n",
    "                entropy_s = entropies[S]\n",
    "            count_s = df[S].count()\n",
    "            keys = df[A].unique()\n",
    "            counts=df[A].value_counts()\n",
    "            data_counts = dict(zip(keys, counts))\n",
    "            try:\n",
    "                for r in data_counts.keys():\n",
    "                    # current probability of class\n",
    "                    p=float(data_counts[r])/sum(counts) \n",
    "                    if type_R == 'IG' :\n",
    "                        summation=summation+p*entropies[A][r]\n",
    "                    else:\n",
    "                        summation=summation+p*entropies[A]\n",
    "            except:\n",
    "                pass\n",
    "        return entropy_s-summation if type_R == 'IG' else entropy_s-summation\n",
    "    else:\n",
    "        return 'error : empty dataframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def get_unique_data_counts(data):\n",
    "    try:\n",
    "        result = {}\n",
    "        if not isinstance(data , pd.Series):\n",
    "            for column in data:\n",
    "                result[column] = __uniqueCounts(data,column)\n",
    "        else:\n",
    "            result[data.name] = dict(zip(list(set(data)), pd.Series(Counter( data ))))\n",
    "        return result\n",
    "    except:\n",
    "        print('column' , ' : ' , column)\n",
    "        print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __uniqueCounts(data_frame, column):\n",
    "    return data_frame.groupby(column).size().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __getSubset(df,column, value):\n",
    "    set1 = df[df[column] == value] #Observations equal to value are in set 1\n",
    "    set2 = df[df[column] != value] #Observations not equal to value are in set2 \n",
    "    return (set1, set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ID3(training_data , target_attribute,root,depth,heuristic='IG',max_dep=[]):\n",
    "    if training_data.empty :\n",
    "        return \n",
    "    else:\n",
    "        classes = __uniqueCounts(training_data,target_attribute)\n",
    "        attributes = list(training_data.columns)[:-1]\n",
    "        if len(classes) == 1:\n",
    "            root.results = list(classes.keys())[0]\n",
    "            root.depth = depth-1\n",
    "            max_dep.append(depth-1)\n",
    "            root.col = None\n",
    "            root.leaf=True\n",
    "            return\n",
    "        elif len(attributes) == 0:\n",
    "            root.results = max(classes, key=classes.get)\n",
    "            root.depth = depth-1\n",
    "            max_dep.append(depth-1)\n",
    "            root.col = None\n",
    "            root.leaf = True\n",
    "            return\n",
    "        else :\n",
    "            max_gain = 0\n",
    "            best_attribute = None\n",
    "            for attribute in attributes:\n",
    "                #print(attribute)\n",
    "                temp_IG = get_InformationGain(training_data,target_attribute,attribute,heuristic)\n",
    "                if temp_IG>=max_gain:\n",
    "                    max_gain = temp_IG\n",
    "                    best_attribute = attribute\n",
    "            root.col=best_attribute\n",
    "            root.depth = depth\n",
    "            root.fb = decisionNode()\n",
    "            root.tb = decisionNode()\n",
    "            root.fb.assignAttributes(value=0,max_sample = max(classes, key=classes.get))\n",
    "            root.tb.assignAttributes(value=1)\n",
    "            unique_values = sorted(training_data[best_attribute].unique())\n",
    "            (set1 , set2) = __getSubset(training_data,best_attribute,unique_values[0])\n",
    "            #print('root.fb' ,' : ' ,root.col , ' : ' , root.value , root.leaf )\n",
    "            ID3(set1.drop(best_attribute,axis=1),target_attribute,root.fb,depth+1)\n",
    "            #print('root.fb.fb' ,' : ' ,root.fb.col , ' : ' , root.fb.value,root.fb.results , root.fb.leaf,root.depth )\n",
    "            ID3(set2.drop(best_attribute,axis=1),target_attribute,root.tb,depth+1)\n",
    "            #print('root.tb.fb' ,' : ' ,root.tb.col , ' : ' , root.tb.value ,root.tb.results, root.tb.leaf , root.depth )\n",
    "    return (root,max_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('training_set.csv')\n",
    "df2 = pd.read_csv('test_set.csv')\n",
    "df3 = pd.read_csv('validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = decisionNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(result,depth)= ID3(df1,'Class',root,1)\n",
    "#(result,depth)= ID3(df1,'Class',root,1,'VI')\n",
    "#max(depth)\n",
    "#Num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-03862ca9a63d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy(df2,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printTab(n):\n",
    "    for i in range(0,n):\n",
    "        print('|--->',end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printTree(root):\n",
    "    if root.depth == 1:\n",
    "        print(root.col , '= ' , end=\"\")\n",
    "    else :\n",
    "        if not root.leaf:\n",
    "            print(root.value , ': \\n' )\n",
    "            printTab(root.depth)\n",
    "            print(root.col ,' = ' , end=\"\")\n",
    "        elif root.col is None:\n",
    "            print(root.value , ' : ' , root.results ,' \\n ' , end=\"\\n\")\n",
    "    if root.fb is not None:\n",
    "        printTree(root.fb)\n",
    "    if root.depth == 1:\n",
    "        print(root.col , '= ' , end=\"\")\n",
    "    else :\n",
    "        if not root.leaf :\n",
    "            printTab(root.depth)\n",
    "            print(root.col ,' = ' , end=\"\")\n",
    "    if root.tb is not None:\n",
    "        printTree(root.tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printTree(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_set , trained_Dtree):\n",
    "    if trained_Dtree.col is None:\n",
    "        return trained_Dtree.results\n",
    "    elif trained_Dtree.leaf :\n",
    "        return trained_Dtree.results\n",
    "    if test_set[trained_Dtree.col] == 0 :\n",
    "        return predict(test_set,trained_Dtree.fb)\n",
    "    else:\n",
    "        return predict(test_set,trained_Dtree.tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(test_data , trained_model):\n",
    "    count = 0\n",
    "    for num in range(0,len(test_data)):\n",
    "        if predict (test_data.loc[num],trained_model) == test_data.loc[num]['Class']:\n",
    "            count = count+1\n",
    "    return (count/len(test_data))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(df2,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[0]['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[4]['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_node_by_leaf(root,node):\n",
    "    leaf=get_leaf_node(node)\n",
    "    if node is None :\n",
    "        return root\n",
    "    if leaf is None :\n",
    "        return root\n",
    "    node.fb = leaf.fb\n",
    "    node.tb = leaf.tb\n",
    "    node.value = leaf.value\n",
    "    node.results = node.sample_max\n",
    "    node.depth = leaf.depth\n",
    "    node.col = leaf.col\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def get_leaf_node(tree):\n",
    "    rand_num = randint(0, 1)\n",
    "    if tree is None:\n",
    "        return tree\n",
    "    if tree.leaf :\n",
    "        return tree\n",
    "    if rand_num == 0:\n",
    "        return get_leaf_node(tree.fb)\n",
    "    else:\n",
    "        return get_leaf_node(tree.tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_node(tree,maxDepth=2):\n",
    "    rand_num = randint(0, 1)\n",
    "    if tree.tb is None or tree.fb is None:\n",
    "        return tree\n",
    "    if tree.depth>=maxDepth or tree.tb.leaf or tree.fb.leaf :\n",
    "        return tree\n",
    "    if rand_num == 0:\n",
    "        return get_random_node(tree.fb)\n",
    "    else:\n",
    "        return get_random_node(tree.tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy(tree):\n",
    "    if tree is None:\n",
    "        return\n",
    "    else :\n",
    "        temp = decisionNode()\n",
    "        temp.col=tree.col # column index of criteria being tested\n",
    "        temp.value=tree.value # vlaue necessary to get a true result\n",
    "        temp.results=tree.results # dict of results for a branch, None for everything except endpoints\n",
    "        temp.leaf = tree.leaf\n",
    "        temp.depth =tree.depth\n",
    "        temp.sample_max = tree.sample_max\n",
    "        temp.tb=copy(tree.tb) # true decision nodes \n",
    "        temp.fb=copy(tree.fb) # false decision nodes\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_pruning(tree,L,K,validation_set):\n",
    "    D_best = tree\n",
    "    acc_b = accuracy(validation_set,D_best)\n",
    "    for i in range(1,L):\n",
    "        D_prime = copy(D_best)\n",
    "        M = randint(1, K)\n",
    "        for j in range(1,M):\n",
    "            node_rand = get_random_node(D_prime,randint(1,15))\n",
    "            if node_rand is None: \n",
    "                break\n",
    "            D_prime=replace_node_by_leaf(D_prime,node_rand)\n",
    "        t=accuracy(validation_set,D_prime)\n",
    "        if t > acc_b :\n",
    "            D_best = D_prime\n",
    "    return D_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.65"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_tree = post_pruning(result,5,14,df3)\n",
    "accuracy(df3,post_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(df2,post_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
